\documentclass[../../rtnotes.tex]{subfiles}
\begin{document}
\section{09/18}
\subsection{The Heisenberg group and the Weyl algebra}
The Heisenberg group is not a semidirect product of $\U(1)$ and $G\times\widehat G$, but by breaking the symmetry of the pair $G,\widehat G$, it is a semidirect product of $\widehat G\times \U(1)$ and $G$. That is, 
\[\Heis \cong G \ltimes_\varphi \widehat G\times \U(1)\]
where $\varphi\colon G\to \Aut(\widehat G\times \U(1))$ is given by $\phi(g)(\hat h,w) = (\hat h,\overline{\chi(g,\hat h)}w)$. Hence the group multiplication is given by 
\[(g,\hat g,z)(h,\hat h,w) = (gh,\hat g \hat h, \overline{\chi(g,\hat h)}zw)\] 
and agrees with the usual one on $\Heis$.

The observations we made last time about viewing genuine representations of $\Heis$ as a sheaf over $G$ in which $\widehat G, \U(1)$ act in a manner that preserve stalks and $G$ acts by moving vectors between stalks can be recast using the above isomorphism. Genuine irreps of $\widehat G\times \U(1)$ of a fixed dimension are in correspondence with (or live over) the elements of $G$, and $G$ acts on the set of irreps by changing the action of $\widehat G$ on them; that is, by exchanging irreps (last time, this was to exchange $W_g$ with $W_{hg}$).

Last time, we saw that the Weyl algebra $D$ on $\mathbb R_x$ was the noncommutative $\mathbb C$-algebra generated by $x$ and $\partial_x$, subject to the relation $\partial_xx-x\partial_x = 1$. It acts on $L^2(\mathbb R)$, but a better space for the Weyl algebra to act on is the Schwartz space $\mathcal S(\mathbb R)$. The Schwartz space contains the $C^\infty$ functions on $\mathbb R$ whose derivatives of all orders decay faster than the reciprocal of any polynomial as $x$ tends to $\pm \infty$. A precise definition of the Schwartz space and its topology is rather cumbersome, so it suffices to think of the functions living in the Schwartz space as ``rapidly decaying smooth functions''. For example, the Gaussian $\exp(-x^2/2)$ belongs to $\mathcal S(\mathbb R)$.

By design, the Schwartz space is a module for the Weyl algebra, since the functions in the Schwartz space and their derivatives rapidly decrease, multiplication by $x$ and differentiation really define an action on $\mathcal S(\mathbb R)$. By taking the continuous dual of the Schwartz space, we obtain the tempered distributions, denoted $\mathcal S'(\mathbb R)$. The tempered distributions $\mathcal S'(\mathbb R)$ is another candidate for the group algebra for $G = \mathbb R_x$. 

From analysis, the Fourier transform defines operators on $L^2(\mathbb R)$ and on $\mathcal S(\mathbb R)$. By taking adjoints, the Fourier transform also defines an operator on $\mathcal S'(\mathbb R)$. So the space of tempered distributions is a very nice place to do harmonic analysis on, and we would like to do something similar in the future for non-Abelian groups.

There are no nonzero finite-dimensional $D$-modules. Suppose $V$ is a finite-dimensional $D$-module. Then
\[\dim(V) = \Tr_V(1) = \Tr_V(\partial_xx-x\partial_x) = \Tr_V(\partial_xx)-\Tr_V(x\partial_x) = \Tr_V(\partial_xx)-\Tr(\partial_xx) = 0\]
This result may be thought of as an algebraic version of the Heisenberg uncertainty principle, since not only can we not simultaneously diagonalize $\partial_x$ and $x$, but we cannot have these operators act on finite dimensional vector spaces.

The exponentials $\exp(iy-)$ of $i\partial_x$ and of $x$ give the translation $\tau_{y}$ and multiplication by the character $\exp(iyx)$, and these generate the Heisenberg group. By starting with a $D$-module, we can obtain a module over $\Heis$ by differentiating the action of $G,\widehat G$ to obtain differentiation and multiplication by $x$. To be careful, we need analysis because $D$-modules are not finite-dimensional.

\subsection{Quick introduction to $D$-modules}
The data of a finitely presented $D$-module is the same as a system of linear differential equations with polynomial coefficients. We will come back to this claim after looking at small examples.

Let $M = D/D(\partial_x-\lambda)$ be a left $D$-module (left, right are important since $D$ is not commutative). Then for some other left $D$-module $F$, which is typically a nice function space, $f\in \Hom_D(M,F)$ can be thought of as a solution to the differential equation $(\partial_x-\lambda)u = 0$ living in $F$. This is because any $f\in \Hom_D(M,F)$ is zero on $D(\partial_x-\lambda)$ and any $f\in \Hom_D(D,F)$ which is zero on $D(\partial_x-\lambda)$ descends to a well-defined homomorphism $f\in \Hom_D(M,F)$. That is, 
\[\Hom_D(M,F)\cong \{f\in \Hom_D(D,F)\mid f(\partial_x-\lambda) = 0\}\]
The map $f\mapsto f(1_M)$ defines an isomorphism of $\Hom_D(D,F)$ with $F$, so in particular 
\[\{f\in \Hom_D(D,F)\mid f(\partial_x-\lambda) = (\partial_x-\lambda)f(1_M) = 0\}\cong \{f\in F\mid (\partial_x-\lambda)f = 0\}\]
So if $F$ is a $D$-module that contains $\exp(\lambda x)$, then $\Hom_D(M,F)$ is $\mathbb C\exp(\lambda x)$, otherwise $\Hom_D(M,F)$ is zero. One example of a $D$-module $F$ that has exponentials is the continuous dual of $C_c^\infty(\mathbb R)$, the usual space of distributions on $\mathbb R$ (analysis shows that $\exp(\lambda x)$ does not define a tempered distribution on $\mathbb R$). As a vector space (or $\mathbb C[x]$-module), the module $M$ is isomorphic to the graded vector space $\mathbb C[x]1_M$. The calculation $(\partial_x-\lambda)x = 1-x\partial_x - x\lambda = 1$ shows that left multiplication by $(\partial_x-\lambda)$ gives maps between graded components of $\mathbb C[x]1_M$:
\[\begin{tikzcd}[ampersand replacement=\&]
	0 \\
	{\mathbb C1_M} \\
	{\mathbb Cx} \\
	\vdots
	\arrow["{(\partial_x-\lambda)}", curve={height=-12pt}, from=2-1, to=1-1]
	\arrow["{(\partial_x-\lambda)}", curve={height=-12pt}, from=3-1, to=2-1]
	\arrow["{(\partial_x-\lambda)}", curve={height=-12pt}, from=4-1, to=3-1]
\end{tikzcd}\]
This graded point of view is interesting because now we can see that if $f\in F$ is a solution to $(\partial_x-\lambda)u = 0$; that is, $f$ is a homomorphism of $D$-modules $D/D(\partial_x-\lambda)\to F$, then $x^nf(x)$ is a solution to $(\partial_x-\lambda)^{n+1}u = 0$. This is because $(\partial_x-\lambda)x^n = 0$ in $M$. So in particular, we recover the expected solutions $x^n\exp(\lambda x)$.

Consider the left $D$-module $M = D/D(x-\lambda)$. Its solutions in $\mathcal S'(\mathbb R)$ are $\mathbb C\delta_\lambda$. As a vector space (or $\mathbb C[\partial_x]$-module), the module $M$ is isomorphic to the graded vector space $\mathbb C[\partial_x]1_M$. We obtain a similar picture as above, with $x$ and $\partial_x$ interchanged. Similarly, solutions to the equation $(x-\lambda)^nu = 0$ are derivatives of $\delta_\lambda$. We actually already observed these facts when discussing the indecomposable representations of $\mathbb R$, from the point of view of Jordan blocks and Fourier duality, so this is just another perspective.

A finitely presented left $D$-module $M$ is a module with the free resolution
\[0\to D^n\xrightarrow P D^m\to M\to 0\]
where $m$ denotes the number of generators of $M$ and the map $P$, which can be thought of as right multiplication by an $n\times m$ matrix $P$ (with entries in $D$), encodes the $n$ relations that the $m$ generators of $M$ are subject to. In other words, $M$ is isomorphic to the left $D$-module $D^m/D^nP$. Like before, if $F$ is a left $D$-module, then $f\in \Hom_D(M,F)$ can be identified with solutions $f = (f_1,\dots,f_m)$ to the system of differential equations
\[\sum_{i=1}^nP_{ij}f_j = 0\quad\text{for }j = 1,\dots,m\]
This is because $f = (f_1,\dots,f_m)\in\Hom_D(M,F)$ is really a homomorphism $f = (f_1,\dots,f_m)$ from $D^m$ to $F$ vanishing on $1_{D^n}P = (\sum_{i=1}^nP_{i1},\dots,\sum_{i=1}^nP_{im})$, and we identify $\Hom_D(D,F)$ with $F$ in the same way as before.

If $D = \mathbb C\abr{x_1,\dots,x_n,\partial_{x_1},\dots,\partial_{x_n}}/([x_i,x_j],[\partial_{x_i},\partial_{x_j}],[\partial_{x_i},x_j]-\delta_{ij}\mid 1\leq i,j\leq n)$, then the data of a finitely presented D-module is the same as a system of linear partial differential equations with polynomial
coefficients.

The Fourier transform takes $\dv{x}$ to $-it$ and $x$ to $-i\dv{t}$. It follows that $1 = \partial_xx-x\partial_x$ is sent to $1 = (-it)(-i\partial_t)-(-i\partial_t)(-it) = \partial_tt-t\partial_t$, so the Fourier transform negates the commutation relation between differentiation and multiplication by the coordinate. Since $\mathcal S'(\mathbb R)$ is a $D$-module, the Fourier transform of $\mathcal S'(\mathbb R)$, which is itself $\mathcal S'(\mathbb R)$, is a $\widehat D = \mathbb C\abr{t,\partial_t}/([\partial_t,t]+1)$-module (a module for some kind of opposite version of $D$). So if $f$ satisfies a linear differential equation with polynomial coefficients $Pu = 0$ for a left $D$-module $M$, then $\hat f$ satisfies the Fourier transformed partial differential equation $\hat P\hat u = 0$, so for the left $D$-module $\widehat M$ which is $M$ with $\partial_x,x$ replaced by $-it,-i\partial_t$.

Indeed, the Gaussian $g = \exp(-x^2/2)$ satisfies the differential equation $(\partial_x+x)u=0$. It defines a tempered distribution as well; that is, $g\in\mathcal S'(\mathbb R)$. The Fourier transform takes this differential equation to $(-it-i\partial_t)\hat u = 0$, so $(\partial_t+t)\hat u = 0$. So the Fourier transform of the Gaussian is itself (we did this calculation before). Consider the element $(\partial_x-x)$ in $M$. Suggestively, it is ``orthogonal'' to the element $(x+\partial_x)$: 
\begin{figure}[h]
	\centering
	\begin{tikzpicture}
	\begin{pgfonlayer}{nodelayer}
		\node [style=none] (0) at (0, 2.5) {};
		\node [style=none] (1) at (2.5, 0) {};
		\node [style=none] (2) at (0, 0) {};
		\node [style=none] (3) at (1.5, 1.5) {};
		\node [style=none] (4) at (1.5, -1.5) {};
		\node [style=none] (5) at (0.5, 2.5) {$\partial_x$};
		\node [style=none] (6) at (2.5, 0.5) {$x$};
		\node [style=none] (7) at (2.25, 1.5) {$x+\partial_x$};
		\node [style=none] (8) at (2.25, -1.5) {$\partial_x-x$};
	\end{pgfonlayer}
	\begin{pgfonlayer}{edgelayer}
		\draw [style=to, draw=red] (2.center) to (4.center);
		\draw [style=to, draw=blue] (2.center) to (3.center);
		\draw [style=to:dash] (2.center) to (0.center);
		\draw [style=to:dash] (2.center) to (1.center);
	\end{pgfonlayer}
\end{tikzpicture}

\end{figure}
The corresponding $D$-module for $g$ is $M= D/D(\partial_x+x)$, which is isomorphic as a vector space to $\mathbb C[x-\partial_x]1$ (the $(x-\partial_x)^i$ form a basis for $M$). The calculation $(\partial_x+x)(x-\partial_x) = 1+x^2-\partial_x^2 = 2 + (x-\partial_x)(\partial_x+x) = 2$ shows that left multiplication by $(\partial_x+x)$ gives maps between graded components of $\mathbb C[x-\partial_x]1$:
\[\begin{tikzcd}[ampersand replacement=\&]
	0 \\
	{\mathbb C1} \\
	{\mathbb C(x-\partial_x)} \\
	\vdots
	\arrow["{(\partial_x+x)}", curve={height=-12pt}, from=2-1, to=1-1]
	\arrow["{(\partial_x+x)}", curve={height=-12pt}, from=3-1, to=2-1]
	\arrow["{(\partial_x+x)}", curve={height=-12pt}, from=4-1, to=3-1]
\end{tikzcd}\]
The homomorphism $S_g\colon M\to \mathcal S'(\mathbb R)$ corresponding to the solution $g$ of the differential equation $(\partial_x+x)u = 0$ is the one where $1\in M$ is sent to $g\in \mathcal S'(\mathbb R)$. Then $(x-\partial_x)$ is sent to $(x-\partial_x)g = 2xg$, and $(x-\partial_x)^2$ is sent to $(x-\partial_x)^2g = (4x^2-2)g$. By continuing this process we recover the \href{https://en.wikipedia.org/wiki/Hermite_polynomials}{physicist's Hermite polynomials} $H_n(x)$: the image of $(x-\partial_x)^n$ is $H_n(x)g$, where the first few Hermite polynomials are
\begin{align*}
	H_0(x) &= 1 & H_1(x) &= 2x\\
	H_2(x) &= 4x^2-2& H_3(x) &=8x^3-12x \\
	H_4(x) &= 16x^4-48x^2+12& H_5(x) &= 32x^5-160x^3+120x
\end{align*}
The Hermite polynomials, like the Chebyshev polynomials of the first kind we found earlier, are special functions. They satisfy nice orthogonality relations and recurrence relations which can of course be obtained through the lens of representation theory. The Hermite polynomials form a basis of $L^2(\mathbb R)$ with weighted inner product $\abr{-,-}_g = \abr{-g,-g}_{L^2(\mathbb R)}$ because they form a maximal orthogonal family. To see this, observe that 
\[(\partial_x+x)(x-\partial_x) = 2 + (x-\partial_x)(\partial_x+x)\]
and that the adjoint differential operator of $(x-\partial_x)$ is $(\partial_x + x)$; that is,
\[\abr{(x-\partial_x)f,h}_{L^2(\mathbb R)} = \abr{f,(\partial_x+x)h}_{L^2(\mathbb R)}\]
Repeated application of these identities will show that
\[\abr{H_j(x),H_i(x)}_g = \abr{H_j(x)g,H_i(x)g}_{L^2(\mathbb R)} = \abr{(x-\partial_x)^jg,(x-\partial_x)^ig}_{L^2(\mathbb R)}\]
is nonzero only if $j = i$.

\subsection{Introduction to $\SU(2)$}
The main groups we would like to get to are $\SU(2)$, $\SO_3(\mathbb R)$, and of course, $\SL_2(\mathbb R)$. By studying the representation theory of the first two groups (which are subgroups of $\SL_2(\mathbb R)$), we will gain some insight for how to study the representation theory of $\SL_2(\mathbb R)$.

By identifying complex numbers $z = x+iy$ with real matrices $\bigl(\!\begin{smallmatrix}
	x & y \\ -y & x
\end{smallmatrix}\!\bigr)$, we can identify $\U(1) = \{z\in\mathbb C\mid \abs{z} = 1\}$ with the real matrix group $\{\bigl(\!\begin{smallmatrix}
	x & y \\ -y & x
\end{smallmatrix}\!\bigr)\}\cap\SL_2(\mathbb R)$. There is a natural complexification of this idea (it's unclear whether this was a pun or not).

One way to describe the quaternions is as a complex matrix group; that is, 
\[\mathbb H = \{\bigl(\!\begin{smallmatrix}
	z & w \\ -\overline w & \overline z
\end{smallmatrix}\!\bigr)\}\]
viewed as a subgroup of the $2\times 2$ complex matrices. The quaternions form an associative, non-commutative $\mathbb C$-algebra which may also be described as an $\mathbb R$-algebra spanned by $\{1,i,j,k\}$ subject to the relations $i^2 = j^2 = k^2 = -1$, $ij=k$, $jk = i$, $ki = j$. The description of $\mathbb H$ as an $\mathbb R$-algebra is convenient since there is a nice way to write the conjugation involution and norm on $\mathbb H$: For $a+bi+cj+dk\in\mathbb H$, $\overline{a+bi+cj+dk} = a-bi-cj-dk$ and $\norm{a+bi+cj+dk}^2 = (a+bi+cj+dk)(\overline{a+bi+cj+dk}) = a^2 + b^2 + c^2 + d^2$. We can also view the quaternions as the complex matrix algebra generated by the matrices $1 = \bigl(\!\begin{smallmatrix}
	1 & 0 \\ 0 & 1
\end{smallmatrix}\!\bigr)$, $i = \bigl(\!\begin{smallmatrix}
	i & 0 \\ 0 & -i
\end{smallmatrix}\!\bigr)$, $j = \bigl(\!\begin{smallmatrix}
	0 & 1 \\ -1 & 0
\end{smallmatrix}\!\bigr)$, $k = \bigl(\!\begin{smallmatrix}
	0 & i \\ i & 0
\end{smallmatrix}\!\bigr)$.

In the same way that we think of $\U(1)$ as the determinant $1$ matrices in $\SL_2(\mathbb R)$, we can define $\SU(2)$ as the unit quaternions; that is, 
\[\SU(2)= \mathbb H\cap \SL_2(\mathbb C)\]
The determinant $1$ matrices $\bigl(\!\begin{smallmatrix}
	z & w \\ -\overline w & \overline z
\end{smallmatrix}\!\bigr)$ are those with $\abs{z}^2+\abs{w}^2=1$; if $z = z_1+iz_2$ and $w = w_1 + iw_2$, then $z_1^2+z_2^2+w_1^2+w_2^2 = 1$. So the elements of $\SU(2)$, the unit quaternions, can be thought of the $3$-sphere $S^3$. 

Related is the group of $2\times 2$ unitary matrices $\U(2)$, whose elements satisfy $U\overline U^\top = \overline U^\top U = 1$ (so $\abs{\det U} = 1$). The group $\SU(2)$ is a subgroup of $\U(2)$, and we can also write $\SU(2) = \U(2)\cap \SL_2(\mathbb C)$.

That we can identify the unit quaternions with $S^3$ shows that we can endow $S^3$ with a group structure. Similarly, the unit magnitude elements of $\mathbb C$ may be identified with $S^1$ to give $S^1$ a group structure, and the same can be said about $S^0$ and the unit magnitude elements $\{-1,1\}$ of $\mathbb R$.

Some easy complex representations of $\SU(2)$ are $\mathbb H\cong\mathbb C^2$, one where $\SU(2)$ acts by left multiplication and another where $\SU(2)$ acts by conjugation. The first representation is irreducible, since any element of a proper subspace of $\mathbb H$ can be translated out of that subspace by a suitably chosen element of $\SU(2)$. The conjugation representation viewed as a real representation is reducible, since by viewing $\mathbb H$ as $\mathbb R^4$, the subspace $\mathbb R1$ is preserved under conjugation by unit quaternions. It is also the case that the complement of $\mathbb R1$, the pure quaternions (which we identify as $\mathbb R^3$ so that $\mathbb H = \mathbb R1\oplus \mathbb R^3$ as a real vector space), is also preserved under conjugation by unit quaternions. This is because for a unit quaternion $q$ and quaternions $g,h$, the real part of $h$ is $(h+\overline{h})/2$ and the pure quaternion part of $h$ is $(h-\overline{h})/2$, conjugation of a product is order-reversing: $\overline{gh}= \overline{h}\overline{g}$, and conjugation by $q$ commutes with conjugation $q\overline{h}q^{-1} = q\overline{h}\overline{q} = \overline{qh\overline{q}} = \overline{qhq^{-1}}$.

That the pure quaternions are a $3$-dimensional real representation of $\SU(2)$ under conjugation is to say there is a particular homomorphism $\SU(2)\to\GL(\mathbb R^3)$ which manifests the conjugation action. Conjugation by (nonzero) quaternions preserves the norm of any quaternion (it is easier to see this by returning to the matrix form of quaternions and observing that conjugation by a quaternion preserves the determinant, since the determinant of a matrix is invariant under conjugation). A calculation (not shown here, but see \href{https://en.wikipedia.org/wiki/Versor#Representation_of_SO(3)}{Wikipedia}) shows that the orientation of a pure quaternion viewed as an element of $\mathbb R^3$ is also preserved under conjugation. It follows that the image of the homomorphism $\SU(2)$ to $\GL(\mathbb R^3)$ is a subgroup of $\SO_3(\mathbb R)$. This amounts to viewing conjugation of pure quaternions by a unit quaternion as rotations of vectors in $\mathbb R^3$.

The map from $\SU(2)$ to $\SO_3(\mathbb R)$ is actually a surjective two-to-one map with kernel $\{\pm 1\}\cong\mathbb Z/2\mathbb Z$. So we get an exact sequence 
\[1\to \{\pm 1\}\to \SU(2)\to\SO_3(\mathbb R)\to 1\]
where $\SO_3(\mathbb R) = \SU(2)/\{\pm 1\}$. By identifying $\SU(2)$ with $S^3$, quotienting out by $\{\pm 1\}$ amounts to identifying antipodal points of $S^3$, so as a topological space, $\SO_3(\mathbb R)$ is identified with $\mathbb{RP}^3$. We say that $\SU(2)$ is a double cover of $\SO_3(\mathbb R)$.

David brought an interesting prop made of a belt and a piece of cardboard that represents the double cover of $\SO_3(\mathbb R)$ by $\SU(2)$. The belt is supposed to keep track of the twisting by $\{\pm 1\}$ and the cardboard is supposed to keep track of the position of an element of $\SO_3(\mathbb R)$. I would like to make a video about this that I can link here.

A fun fact: Let $u$ be a pure quaternion of unit length and let $g_\theta = \cos(\theta/2) + \sin(\theta/2)u$. Then $g_\theta$ is a unit quaternion and conjugation of a pure quaternion $v$ by $g_\theta$ (or $-g_\theta$) can be viewed in $\mathbb R^3$ (viewing $u,v$ as elements of $\mathbb R^3$) as rotating $v$ by $\theta$ radians about the axis $u$ (i.e. counterclockwise about $u$ if we move our point of view so that $u$ points towards us).

By letting $\theta$ vary, we can identify $\{g_\theta\}\subset \SU(2) = S^3$ with a copy of $\U(1)=S^1$. Then we can draw the commutative cube
% https://q.uiver.app/#q=WzAsOCxbMCwxLCJcXFUoMSkiXSxbMSwwLCJcXG1hdGhiYiBDXlxcdGltZXMiXSxbMywwLCJcXFNMXzIoXFxtYXRoYmIgQykiXSxbMiwxLCJcXFNVXzJcXGNvbmcgU14zIl0sWzAsMywiXFxVKDEpL1xce1xccG0gMVxcfSJdLFsyLDMsIlxcU09fMlxcY29uZyBcXG1hdGhiYntSUH1eMyJdLFsxLDIsIlxcbWF0aGJiIENeXFx0aW1lcy9cXHtcXHBtIDFcXH0iXSxbMywyLCJcXFNMXzIoXFxtYXRoYmIgQykvXFx7XFxwbSAxXFx9XFxjb25nIFxcUFNMXzIoXFxtYXRoYmIgQykiXSxbMCw0XSxbMCwxXSxbMywyXSxbMSwyXSxbNiw3XSxbMCwzXSxbNCw2XSxbNSw3XSxbMiw3XSxbMyw1XSxbNCw1XSxbMSw2XV0=
\[\begin{tikzcd}[ampersand replacement=\&]
	\& {\mathbb C^\times} \&\& {\SL_2(\mathbb C)} \\
	{\U(1)\cong S^1} \&\& {\SU(2)\cong S^3} \\
	\& {\mathbb C^\times/\{\pm 1\}} \&\& {\SL_2(\mathbb C)/\{\pm 1\}\cong \PSL_2(\mathbb C)} \\
	{\U(1)/\{\pm 1\}} \&\& {\SO_3(\mathbb R)\cong \mathbb{RP}^3}
	\arrow[from=1-2, to=1-4]
	\arrow[from=1-2, to=3-2]
	\arrow[from=1-4, to=3-4]
	\arrow[from=2-1, to=1-2]
	\arrow[from=2-1, to=2-3]
	\arrow[from=2-1, to=4-1]
	\arrow[from=2-3, to=1-4]
	\arrow[from=2-3, to=4-3]
	\arrow[from=3-2, to=3-4]
	\arrow[from=4-1, to=3-2]
	\arrow[from=4-1, to=4-3]
	\arrow[from=4-3, to=3-4]
\end{tikzcd}\]
We will try to study the representation theory of $\SU(2)$ and $\SO_3(\mathbb R)$ by first using the representation theory of $\U(1)$, which we have already studied in detail.
\end{document}